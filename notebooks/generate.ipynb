{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e2c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this cell if running in Google Colab\n",
    "!pip install clinicadl==1.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6535c01d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Generate a synthetic dataset\n",
    "\n",
    "\n",
    "Looking for new network architectures to improve performance on a\n",
    "deep learning task implies testing different sets of hyperparameters. This\n",
    "takes a lot of time and we often end up with networks that don't\n",
    "converge.  To avoid this pitfall, it is often advised to simplify the problem:\n",
    "focus on a subset of data or a task that is more tractable than\n",
    "the one that is currently explored. This is the purpose of `clinicadl\n",
    "generate` which creates synthetic, tractable data from real data to\n",
    "check that developed networks are working on this simple case before going\n",
    "further.\n",
    "\n",
    "With ClinicaDL, you can generate three types of synthetic data sets for a\n",
    "binary classification task depending on the option chosen: `trivial`, `random` or\n",
    "`shepplogan`.\n",
    "\n",
    "If you ran the previous notebook, you must have a folder called\n",
    "`CAPS_example` in the `data_oasis` directory (otherwise uncomment the next cell\n",
    "to download a local version of the necessary folders)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47318d40",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "!curl -k https://aramislab.paris.inria.fr/clinicadl/files/data/handbook_2023/data_oasis/CAPS_example.tar.gz -o oasisCaps.tar.gz\n",
    "!tar xf oasisCaps.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae43371d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Generate trivial data\n",
    "\n",
    "Tractable data can be generated from real data with ClinicaDL. The command\n",
    "generates a synthetic dataset for a binary classification task from a\n",
    "CAPS-formatted dataset. It produces a new CAPS containing trivial data which\n",
    "should be perfectly classified. Each label corresponds to brain images whose\n",
    "intensities in the right or the left hemisphere were strongly decreased.\n",
    "Trivial data is useful for debugging a framework: hyper parameters can be\n",
    "more easily tested as fewer data samples are required and convergence should\n",
    "be reached faster as the classification task is simpler.\n",
    "\n",
    "<img src=\"../images/generate_trivial.png\" alt=\"generate trivial\" style=\"height: 350px; margin: 10px; text-align: center;\">\n",
    "\n",
    "```{warning}\n",
    "You need to execute the `clinica run` pipeline before running this task.  \n",
    "Moreover, the trivial option can synthesize at most n images per label, \n",
    "where n is the total number of images in the input CAPS.\n",
    "```\n",
    "### Running the task\n",
    "\n",
    "```bash\n",
    "clinicadl generate trivial <caps_directory> <output_directory> --n_subjects <n_subjects>\n",
    "```\n",
    "where:\n",
    "\n",
    "- `caps_directory` is the output folder containing the results of `clinica run` in a\n",
    "[CAPS](https://aramislab.paris.inria.fr/clinica/docs/public/latest/CAPS/Introduction/) hierarchy,\n",
    "- `output_directory` is the folder where the synthetic CAPS is stored,\n",
    "- `n_subjects` is the number of subjects per label in the synthetic dataset.\n",
    "Default value: 300.\n",
    "\n",
    "```{warning}\n",
    "`n_subjects` cannot be higher than the number of subjects in the initial\n",
    "dataset. Indeed in each synthetic class, each synthetic image is derived \n",
    "from a real image.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24375018",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "!clinicadl generate trivial data_oasis/CAPS_example data/synthetic --n_subjects 4 --preprocessing t1-linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e3639",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Reproduce the tsv file system necessary for training\n",
    "\n",
    "In order to train a network, meta data must be organized in a file system\n",
    "generated by `clinicadl tsvtools`. For more information on the following\n",
    "commands, please refer to the section [Define your\n",
    "population](./label_extraction.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db02b1ea",
   "metadata": {},
   "source": [
    "#### Get the labels AD and CN\n",
    "`get-labels` command needs a BIDS folder as an argument in order to create the\n",
    "`missing_mods` directory and the `merged_tsv` file, but if you already \n",
    "have these, you can give an empty folder as argument and provide the paths \n",
    "to the required files separately as keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56525e32",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "!mkdir data/fake_bids\n",
    "!clinicadl tsvtools get-labels data/fake_bids data --missing_mods data/synthetic/missing_mods --merged_tsv data/synthetic/data.tsv --modality synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a6729",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Split train and test data\n",
    "!clinicadl tsvtools split data/labels.tsv --n_test 0.25 --subset_name test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abb1c9a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Split train and validation data in a 3-fold cross-validation\n",
    "!clinicadl tsvtools kfold data/split/train.tsv --n_splits 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a6fe39",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Train a model on synthetic data\n",
    "\n",
    "Once data was generated and split, it is possible to train a model using\n",
    "`clinicadl train` and evaluate its performance with `clinicadl interpret`. For\n",
    "more information on the following command lines please read the sections\n",
    "[Classification with a CNN on 2D slice](./training_classification.ipynb) and\n",
    "[Regression with 3D images](./training_regression.ipynb).\n",
    "\n",
    "The following `clinicadl train` command uses a pre-build architecture of ClinicaDL `Conv4_FC3`.\n",
    "You can also implement your own models by following the instructions of [this\n",
    "section](./training_custom.ipynb).\n",
    "\n",
    "First, we need to run `prepare-data` to extract the tensors from the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4ad49b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "!clinicadl prepare-data image data/synthetic t1-linear --extract_json extract_T1linear_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eba2f26",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Then, we will train the network with the synthetic data. If you failed to generate a trivial dataset, \n",
    "please uncomment the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7308dc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# !curl -k https://aramislab.paris.inria.fr/clinicadl/files/handbook_2023/data/synthetic.tar.gz -o synthetic.tar.gz\n",
    "# !mkdir data\n",
    "# !tar xf synthetic.tar.gz -C data\n",
    "# !mkdir data/fake_bids\n",
    "# !clinicadl tsvtools get-labels data/fake_bids data --missing_mods data/synthetic/missing_mods --merged_tsv data/synthetic/data.tsv --modality synthetic\n",
    "# !clinicadl tsvtools split data/labels.tsv --n_test 0.25 --subset_name test\n",
    "# !clinicadl tsvtools kfold data/split/train.tsv --n_splits 3\n",
    "# # no need to run prepare-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba6a82",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Train a network with synthetic data (remove --no-gpu option if you do have access to a gpu)\n",
    "!clinicadl train classification data/synthetic extract_T1linear_image data/split/3_fold data/synthetic_maps --architecture Conv4_FC3 --n_splits 3 --split 0 --no-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd122070",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "As the number of images is very small (4 per class), we do not rely on the\n",
    "accuracy to select the model. Instead we evaluate the model which obtained the\n",
    "best loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e0cdee",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Evaluate the network performance on the 2 test images\n",
    "!clinicadl predict data/synthetic_maps test --caps_directory ./data/synthetic --participants_tsv ./data/split/test_baseline.tsv --selection_metrics \"loss\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f617fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fold = 0\n",
    "\n",
    "predictions = pd.read_csv(\"./data/synthetic_maps/split-%i/best-loss/test/test_image_level_prediction.tsv\" % fold, sep=\"\\t\")\n",
    "display(predictions)\n",
    "\n",
    "\n",
    "metrics = pd.read_csv(\"./data/synthetic_maps/split-%i/best-loss/test/test_image_level_metrics.tsv\" % fold, sep=\"\\t\")\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af9c02",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Generate random data\n",
    "\n",
    "This command generates a synthetic dataset for a binary classification task\n",
    "from a CAPS-formatted dataset. \n",
    "It produces a new CAPS containing random data which cannot be correctly\n",
    "classified. All the images from this dataset comes from the same image to\n",
    "which random noise is added. Then the images are randomly distributed between\n",
    "the two labels\n",
    "\n",
    "<img src=\"../images/generate_random.png\" alt=\"generate random\" style=\"height: 350px; margin: 10px; text-align: center;\">\n",
    "\n",
    "```{warning}\n",
    "You need to execute the `clinica run` pipeline prior to running this task.  \n",
    "Moreover, the random option can synthesize as\n",
    "many images as wanted with only one input image.\n",
    "```\n",
    "### Running the task\n",
    "\n",
    "```bash\n",
    "clinicadl generate random <caps_directory> <generated_caps_directory> \n",
    "```\n",
    "where:\n",
    "\n",
    "- `caps_directory` is the output folder containing the results of `clinica run` in a\n",
    "[CAPS](https://aramislab.paris.inria.fr/clinica/docs/public/latest/CAPS/Introduction/) hierarchy,\n",
    "- `generated_caps_directory` is the folder where the synthetic CAPS is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf4cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "!clinicadl generate random data_oasis/CAPS_example data/CAPS_random --n_subjects 5 --preprocessing t1-linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a49d044",
   "metadata": {},
   "source": [
    "The command generates 3D images of same size as the input images formatted as\n",
    "NIfTI files. Then the `clinicadl prepare-data` command must be run to use the\n",
    "synthetic data with ClinicaDL. Results are stored in the same folder hierarchy\n",
    "as the input folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e241670",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Generate Shepp-Logan data\n",
    "\n",
    "This command is named after the Shepp-Logan phantom, a standard image to test\n",
    "image reconstruction algorithms.\n",
    "It creates three subtypes of 2D images distributed between two labels. These\n",
    "three subtypes can be separated according to the top (framed in blue) and\n",
    "bottom (framed in orange) regions: \n",
    "- **subtype 0**: Top and Bottom regions are of maximum size, \n",
    "- **subtype 1**: Top region has its maximum size but Bottom is atrophied, \n",
    "- **subtype 2**: Bottom region has its maximum size but Top is atrophied.\n",
    "\n",
    "<img src=\"../images/generate_shepplogan.png\" alt=\"generate shepplogan\" style=\"height: 250px; margin: 5px; text-align: center;\">\n",
    "\n",
    "These three subtypes are spread between two labels which mimic the binary\n",
    "classification between Alzheimer's disease patients (AD) with heterogeneous\n",
    "phenotypes and cognitively normal participants (CN). Default distributions are\n",
    "the following:\n",
    "\n",
    "| subtype |   0  |   1  |   2  |\n",
    "|---------|------|------|------|\n",
    "|    AD   |  5%  | 85%  | 10%  |\n",
    "|    CN   | 100% |  0%  |  0%  |\n",
    "\n",
    "The CN label is homogeneous, while the AD label is composed of a typical\n",
    "subtype (1), an atypical subtype (2) and normal looking images (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed71edc",
   "metadata": {},
   "source": [
    "### Running the task\n",
    "```Text\n",
    "clinicadl generate shepplogan <generated_caps_directory> \n",
    "```\n",
    "where:\n",
    "- `generated_caps_directory` is the folder where the synthetic CAPS is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9991f499",
   "metadata": {},
   "outputs": [],
   "source": [
    "!clinicadl generate shepplogan data/CAPS_shepplogan --n_subjects 3"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
